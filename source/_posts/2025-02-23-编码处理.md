---
title: C++中的字符编码（二）
layout: post
date: 2025-02-23
---

## 概述

在这个系列的第一篇中，我从一个简单例子出发，从C++标准编译流程的字符处理角度出发称述了C++编译过程和运行时（字符类）中的字符转换行为，并分阶段罗列了可能发生的字符集编码转换和工具链的行为，然而，并不是只有编译和字符串类对象初始化时才涉及字符转换，在日常的业务逻辑中，也经常出现需要处理编码或编码转换的情况：有些字符串来自第三方库或Web API的调用，它们的编码是由实现给定的；有些时候，业务逻辑中可能需要以一种中间形式保存字符串并在其使用时按需转换；在处理多语言的应用时，可能需要在不同的平台和不同的本地设置的操作系统下工作；这些情况对于字符串的表示和转换提出了要求。

字符集编码处理的需求如此广泛，自然在C++生态中也有诸多设施对处理字符集编码提供了支持，第二篇文章正是要讨论这些设施，通过这篇文章，要分析以下问题：

* 从C++11到C++23，C++语言核心和标准库为字符集编码处理提供了哪些支持？
* 标准库通过怎样的概念体系构建了对字符集编码的支持？
* 标准库对编码的支持在实现方面长期被人诟病，这是为什么？
* 在不同的C++版本中，对字符集编码的处理有何变化，是什么推动了这些变化？
* 作为一门生态广泛的语言，第三方库和平台为C++的编码处理提出了哪些方案？

## 语言核心

C语言在字符处理方面有简单的抽象，它使用8位字符类型存储单个字符，并利用字符数组来处理字符串，C++几乎继承了C语言的一切，也包括其处理的字符串的方式，C++的语核没有提供额外的字符串的支持。

长期以来，C和C++都没有将输入字符集和执行字符集和对应的编码以标准的形式规定下来，而语言本身仅仅支持8位字符，这仅仅可以支持ASCII这样的单字节字符集编码，而对于大多数ANSI字符，都需要用多个8位字符来保存，时常有人说C和C++程序员处理的都是字节数组而不是字符数组或字符串，也是出于这个原因；

为了覆盖更大的编码区间，C和C++引入**宽字符**的概念对其进行处理，标准要求实现定义名为`wchar_t`的类型以覆盖多于一个字节的字符，但是宽字符的长度和编码实现留给了具体的平台，标准仅仅要求宽字符是基本字符的超集；尽管标准要求如此宽松，看上去不难达到，但是因为一些历史原因，windows选择了与基本字符集不兼容的USC-2/UTF-16作为其平台的内核编码和宽字符集编码，工具链实现只能选择接纳，尽管它不太满足标准的要求。

到C++11，C++对于Unicode的支持越发重视，其中最主要的变化就是在语言核心引入了新的字符类型以实现对Unicode及其多种编码方式的全面支持，使特定的编码方式和特定的类型绑定，同时也引入了对应的字面量类型支持方便的构建使用特定编码的字符串，这些行为实际上是执行字符集的一部分，这些对应的字符串可以由源字符集编码中间形式转换而来，在C++11的设计中，16位的`char16_t`用于存储UTF-16编码的字符，32位的`char32_t`用于存储UTF-32编码的字符，8位的`char`可以用于保存ASCII字符、UTF-8编码的字符或传统的ANSI编码的字符。

C++11对于字符处理的根本问题是`char`类型的多重语义：传统上，`char`类型用于支持ASCII字符和ANSI字符，前者是基本字符集的子集，后者是由本地配置和扩展字符集决定的，在Unicode项目和USC项目出现之前，C和C++作为Native语言，没有一个重的运行时去屏蔽平台带来的影响，使用由Locale决定的ANSI编码是其支持多语言、多文化背景的主要方法；而在C++11中，`char`不仅需要为表示ASCII字符和ANSI字符提供兼容性，还需要保存UTF-8编码的字符，如果在函数的参数或返回值中出现一个`char*`类型的变量，函数的调用者很难直接的知道这个字符数组中的字符使用何种编码，这给字符编码处理带来了混乱；

实际上，标准委员会也认识到了这个问题，引入专用于处理UTF-8编码字符的字符类型刻不容缓，于是，在C++20，`char8_t`类型加入语言核心，专用于处理UTF-8编码的字符串；然而，这一行为在解决`char`类型多重语义问题的同时，又导致了破坏性更新，从C++11起，`char[]`类型的变量可以被`u8`字面量初始化，但是随着`char8_t`的出现，这一行为就不合理了，于是从C++20起，这一行为被移除，取而代之的是应该用`u8`字面量初始化`char8_t[]`类型的变量，这带来了一些兼容性问题，如果C++1x代码想要升级到，许多C++1x的代码升级到C++20的成本变得更高了；

## 标准字符串和流

对于C++来说，要想相对方便地处理字符串，最重要的工具就是标准库的字符串类，它其实是个字符类模板，有如下定义：

```C++
std::basic_string<char_type, std::char_traits<char_type>, std::allocator<char_type>>
```

`std::string`和`std::wstring`作为历史最久远、最常用的两个字符串类，正是该模板对`char`和`wchar_t`类型的特化；

尽管C++标准库总是有复杂过度之嫌，但是可以看到，将字符串定义为模板是非常灵活的，可以通过各类字符类型的特化来按需定制，在C++11之后，随着`char16_t`、`char32_t`、`char8_t`的引入，标准库也顺理成章的提供了三种字符类型对应的特化字符串`std::u16string`、`std::u32string`和`std::u8string`，这看上去很美好，通过字符串类模板的几种特化，可以处理不同的编码的字符串，即使未来引入其他字符编码也可以通过模板参数来提供支持。

但实际情况并没有这么理想，问题主要出在C++对“字符”这个概念的抽象上，一般地来说，我们所认为的字符，是一种足够大的集，大到拥有足够多的值，以确保每个值都只有唯一一个码点与之对应，但是标准定义的5中字符类型中，只有`char32_t`使用一个值就足以表示Unicode中的所有字符，对于`char16_t`来说情况稍差点，但对于大多数常用字，一个字符也足以表示了，对于ANSI和UTF-8这样的多字节编码，使用一个值和一个码点对应是不可能的，它们需要若干个值才能表示一个字符，这与我们一开始提到的字符概念完全不同，给字符处理带来了很大困难。基于迭代器和范围（C++20）的模板库算法均以遍历单个容器元素的方式运行，对于标准库算法来说它仅能处理字节而不是字符；这意味这从标准库设施的角度来看，多字节字符串类的实际抽象并不是字符的数组，而是字节的数组，这也直接导致了标准库字符串和字符串算法长期以来都很难有分割方法的支持，组合使用多个算法扫描并处理字符串是可行的，但是这并不方便，如果曾经使用过其他语言的字符串类，一定能感觉到这些处理方式不太直觉；

除了字符串本身之外，另一个很大的问题出现在流类对不同字符的支持上，**基于流的IO设施**是C++标准库输入输出库的一部分，早在C with class时代，C++之父B·S·设计了最初的流类，在后来的十几年里，它逐步发展壮大，这一部分库提供了最常用的IO工具；然而，IO流是和字符类型相关联的，例如，标准输出流`std::cout`的类型是`std::ostream`，它的定义如下：

```c++
template<
    class CharT,
    class Traits = std::char_traits<CharT>
> class basic_ostream : virtual public std::basic_ios<CharT, Traits>
```

模板参数`charT`的出现，表面流类型实际上与字符类型关联，实际上，一个流类型的流插入或流提取所能接受的参数必须是被`charT`类型的字符类型特化的字符串模板或该类型的字符数组，这也就意味着如果没有`char16_t`、`char32_t`等类型特化的流对象支持，这些字符类型所对应的字符串特化和字符数组可能连输入输出都做不到，实际情况也正是如此，语言定义了多种不同的字符类型，但标准库标准却没有要求实现对应的流特化，直到今天，流类中仍然仅有针对`char`和`wchar_t`的特化，也就是说，即使使用字符字面量正确初始化了`std::u8string`、`std::u16string`和`std::u32string`，实操中也没有任何配套的设施可以供我们输入输出它；

为什么标准库不能设计一个可以接受任意字符串的流类呢？保持与字符串模板相同的扩展性是最核心的因素，看待这个问题的另外一个角度是不同流类型的差异：如果需要为一种字符类型提供特化，那么在流基类的基础上需要实现什么？其中最重要的就是将输入流的字符转换为更底层的IO设备所需要的多字节字符表示，这个行为是自洽的，一个程序应当有稳定、唯一的内部字符表示，传统上这样的表示一般是一种由Locale决定的编码，将外部不同来源（磁盘文件、网络、进程间通信等）的不同编码的字符转换为程序内部表示的字符串，或者将程序内部表示的字符串转换为可以被其他目标接受的字符正是流的任务，为了做到这一点，流维护了用于存储和转换字符编码的缓冲区，这个缓冲区的定义是：

```C++
template<
    class CharT,
    class Traits = std::char_traits<CharT>
> class basic_streambuf;
```

在另外一些派生的流类中，它们可能定义自己的流缓冲区，这些缓冲区是从`basic_streambuf`派生的，如文件流的缓冲区：

```C++
template<
    class CharT,
    class Traits = std::char_traits<CharT>
> class basic_filebuf : public std::basic_streambuf<CharT, Traits>
```

这些流缓冲区使用一组公共概念，即**控制序列**和**关联序列**，其中，控制序列是流缓冲区类保存的一个字符数组，其字符类型为`charT`，而关联序列是字符的源（对于输入流）或接收器（对于输出流），而流缓冲区保存了一个`std::codecvt`对象用于控制序列字符类型和关联序列字符类型之间的转换，它是本地化库的一部分，要了解`std::codecvt`的行为和可能存在的问题，就要关注本地化库的标准和实现。

## Locale

Locale是最广泛的处理国际化和本地化的机制，它不是C++的发明，实际上，使用Locale概念来提供多语言、多文化支持的方式最早可以追溯到Unix标准化时期，在后来，它逐渐成为一项被多种操作系统和编程语言普遍接受的机制，C++的Locale库诞生与1998年，这一年，标准委员会通过了第一个C++标准，Locale成为了最早的标准库组件之一。

从概念上看，标准库所定义的Locale，是一个扩展性很强的框架，一个Locale对象表示一系列与区域相关的子单元，每一个子单元都代表了区域设置的一个“方面”，称**刻面（Facet）**，正如它的名字那样，每一个刻面都分别负责处理区域设置中一个正交的部分，所有刻面的行为之和即Locale对象的行为，就像多面体的每一个面加起来构成了整个多面体一样，这些刻面可以通过刻面索引来检查和获取，所以也说Locale是刻面的索引集。

标准库标准文档定义了一系列标准刻面，也就是说，标准库认为，国家和地区之间的文化差异至少体现在若干个方面，标准要求每一个标准库实现都务必实现以下刻面：控制字符比较和排序的`collate`刻面，控制字符分类和大小写转换的`ctype`刻面，表示货币面值和单位的`monetary`刻面，表示数字分类和格式的`numeric`刻面，表示字符资源和翻译的`messages`刻面，表示时间格式化的`time`刻面，最后是这篇文章的主角：控制字符转换的`codecvt`刻面：

```C++
template<class InternT, class ExternT, class StateT> 
class codecvt;
```

从签名上来看，一个`codecvt`主要由三部分决定：内部字符类型、外部字符类型和一个状态，`codevct`提供了两个方法用于在两种字符类型之间转换：

```c++
result std::codecvt<InternT,ExternT,StateT>::out( StateT& state,
            const InternT* from,
            const InternT* from_end,
            const InternT*& from_next,
            ExternT* to,
            ExternT* to_end,
            ExternT*& to_next ) const;
```

用于将内部字符类型字符串转换为外部字符类型字符串，而：

```C++
result std::codecvt<InternT,ExternT,StateT>::in( StateT& state,
           const ExternT* from,
           const ExternT* from_end,
           const ExternT*& from_next,
           InternT* to,
           InternT* to_end,
           InternT*& to_next ) const;
```

用于将外部字符类型字符串转换为内部字符类型字符串，其中，如果两个类型相同，则称为**恒等转换**，恒等转换没有任何编码转换行为。

这看起来很美好，但是就像一切在C++中看起来很美好的事情一样，`std::codecvt`的缺陷也相当明显，最关键的问题在于，`std::codecvt`是从`std::locale`获得的，可是在C++标准中，并没有明确规定标准库的实现需要支持哪些名称的Locale，换言之，Locale名称是非标准化的，在对`std::locale`构造函数行为的描述中，需要系统平台支持对应的Locale名称，才能构造指定名称的Locale。例如，在Windows 10之前，windows根本不支持UTF-8 Locale，根本无法构造UTF-8的`std::locale`，这样就意味着没法得到一个转换目标为UTF-8的`codecvt`，另外一些移植到Windows上的GCC工具链不支持除了`C`和`POXIS`之外的任何Locale，而这两个基本Locale仅表示区域设置的中立最小集，几乎不支持任何与区域相关的设置，这种实现上的巨大差异导致很难通过`std::locale`来进行跨平台的字符转换。

即使是对于标准明确要求实现的`std::codecvt`特化，实际上也很难使用，这是因为标准所要求的`std::codecvt`特化，在最近10年内被反复不断地新增又废止，实践中没有一个特化可以活着走完C++11到C++23，早在C++11中，为了配合新的`char16_t`和`char32_t`，`std::codecvt`引入了新的特化：

```C++
std::codecvt<char16_t, char, std::mbstate_t>
```

和

```C++
std::codecvt<char32_t, char, std::mbstate_t>
```

这一组`std::codecvt`用于处理UTF-16、UTF-32和UTF-8之间的转换，但是如之前所说，使用`char`类型同时处理ASCII、ANSI、UTF-8是不合适的，随着C++20中`char8_t`的引入，这一组使用了`char`类型处理UTF-8的API只能因为行为不一致而退出舞台，它们的代替特化：

```C++
 std::codecvt<char16_t, char8_t, std::mbstate_t>
```

和

```C++
std::codecvt<char32_t, char8_t, std::mbstate_t>
```

在C++20加入，但是这组API在加入不久就被弃用了，原因是由于`std::codecvt`类型需要支撑流中的字符转换，所以其外部字符类型和对应的编码应该是由本地设置决定的，类似传统的`char`和`wchar_t`刻面：

```C++
std::codecvt<char, char, std::mbstate_t> // 恒等转换
std::codecvt<wchar_t, char, std::mbstate_t> // wchar_t和char相互转换，其中char类型支持ANSI字符集编码
```

可能在C++标准委员会心中，C++需要的实际上是如下的一些刻面：

```c++
std::codecvt<char32_t, char, std::mbstate_t>
std::codecvt<char16_t, char, std::mbstate_t>
std::codecvt<char8_t, char, std::mbstate_t> 
```

需要注意的是，虽然前两个刻面和C++11中的两个刻面特化是同名的，但是它们的语义并不一致；

而C++20加入的这一组API规定的外部字符编码必须是UTF-8，因此，这一组特化也被弃用了；

站在C++26这个时间节点来看，虽然引入`char8_t`确实明确了UTF-8字符的支持和处理，但是仍然可以看到一些矛盾，ANSI字符集信息来自于系统Locale，但是系统Locale本身也可以是UTF-8，也就是说，外部字符类型是`char`的`codecvt`的外部字符集编码也可以是UTF-8，这样实际上就会在运行时通过转换得到一个使用UTF-8表示的`char[]`或者`std::string`；这个问题的根源是对于ANSI、UTF-8这样的多字节字符集来说，它们的区别表现在运行时的Locale和值上，纯粹的编译时类型特性可能很难区分它们，在编译时，它们都表现为包含多个字节的字符单元，所以使用多个单字节单元来处理是合适的，对于每种编码来说，这个“单字节单元”完全可以是同一类型，而在运行时，用于区分它们的Locale本身是依赖字符类型来区分的，这就是说要为每种编码都定义一种独特的单字节单元类型；但实际的情况是，只有UTF-8有专用的`char8_t`与之对应，而其它ANSI字符统一使用`char`，这反映的是运行时和编译时对“字符编码类型”的抽象不完全一致，这种潜在的矛盾可能长期存在；另外一些语言和库从单/多/双/四字节字符串的角度来考虑字符串的概念结构和接口，它们用字节数组来支持像ANSI、ASCII、UTF-8这样的单/多字节字符，而不是将单个字节视为字符，这样的处理相比标准库要更加自洽。

值得一提的是，通过构造`std::locale`再通过刻面索引并非获取`std::codecvt`的唯一途径，在C++11中，标准库曾经通过一组与Locale无关的`std::codecvt`，它们都是通过派生实现的，并且提供了给定Unicode编码之间的转换，标准强制要求标准库实现它们，并且确保实现在所有平台上都有一致的行为，这些实现通过`<codecvt>`头文件提供：

```C++
template<
    class Elem,
    unsigned long Maxcode = 0x10ffff,
    std::codecvt_mode Mode = (std::codecvt_mode)0 >
class codecvt_utf8: public std::codecvt<Elem, char, std::mbstate_t>;

template<
    class Elem,
    unsigned long Maxcode = 0x10ffff,
    std::codecvt_mode Mode = (std::codecvt_mode)0 >
class codecvt_utf16: public std::codecvt<Elem, char, std::mbstate_t>;

template<
    class Elem,
    unsigned long Maxcode = 0x10ffff,
    std::codecvt_mode Mode = (std::codecvt_mode)0 >
class codecvt_utf8_utf16: public std::codecvt<Elem, char, std::mbstate_t>;
```

这一组API提供了在不同的Unicode/UCS字符集之间转换的手段，这些转换是与Locale和ANSI字符集编码无关的，理论上这些工具可以很好的支持不同Unicode/UCS字符集编码，但实际的情况是，这些工具至少在两个方面存在问题：

* 对于双字节字符，标准要求其支持USC-2，但是如今UCS-2已经成为一种过时的编码，并且被它的超集UTF-16代替，尽管有些标准库实现会将它直接实现为支持UTF-16的，但是这毕竟不是标准行为；
* C++20要求使用`char8_t`存储UTF-8字符，而这组工具仍使用`char`；

所以这组工具也在C++17中弃用，并在C++26移除了；

但并非在C++17之后就不能处理字符转换，这里离谱的就要来了，在C++17中，标准库增加了文件系统库，文件系统库中有一个表示路径的类`std::filesystem::path`，标准规定该类应提供一系列方法，将该类对象存储的路径转换为不同类型的字符串表示，如下：

```C++
std::string string() const;
std::wstring wstring() const;
std::u16string u16string() const;
std::u32string u32string() const;
std::string u8string() const; //C++17至C++20
std::u8string u8string() const; //C++20起
```

这一组API将`path`对象的内部路径表示转换为字符串类表示；

标准还规定`path`的构造函数中，有一构造函数模板如下：

```C++
template<class Source> std::filesystem::path::path(const Source& source, format fmt = auto_format);
```

该模板中，`Source`类型可以是`std::basic_string`或`std::basic_string_view`模板的一个特化，包括`char`、`char16_t`、`char32_t`和`wchar_t`，C++20起还应该包含`char8_t`，实例化而来的构造函数应该能解析并将`source`转换为其内部表示，所以`path`完美的符合了一个字符串所要满足的所有条件，所以：

````C++
using String = std::filesystem::path;
````

似乎真的有点道理；

单纯地从这一组方法上来看，`path`可以将多种编码的字符串转换为其固定的内部表示，再将内部表示转换为多种不同的字符串，这几乎就是一个完美的编码转换器；

但问题是，`std::codecvt`中除了恒等转换和本地宽-窄字符转换之外的特化都废弃了，`path`拿什么做的编码转换？答案是自己内部实现的，标准从来没有规定过编码转换只能通过`std::codecvt`进行，在流类中，标准明确指出了流缓冲区依赖`std::codecvt`进行编码转换，但是对于`path`并没有做这样的规定，所以它不受`std::codecvt`实现的限制。

## 第三方库的解决方案

由于种种原因，C++标准库的字符编码处理设施总是立了又废废了又立，没有一个稳定的解决方案，但是正如上文所说，`std::locale`本身可能不是很好的Locale实现，但它提供了一个扩展性良好的框架，第三方库可以实现自己的刻面并将将刻面包含在`std::locale`对象中，并通过标准库定义的Locale接口访问并使用它们，Boost Locale就是这样的一个例子，从基础概念来看，Boost Locale并未提供自己的Locale类，如`boost::locale`，而是提供了一个Locale生成器`boost::locale::generator`，通过这个类，可以生成一个`std::locale`类实例，但不同于通过构造函数生成的对象，这个对象保存了由Boost Locale实现的刻面，因此提供了比标准库更全面的功能。

虽然说是保存了由Boost Locale实现的刻面，但实际各个刻面中承担其核心职能的部分往往不是Boost Locale提供的，事实上，Boost Locale也借助第三方库的功能，这听上去比较平常，毕竟没人规定一个库不能依赖其他库，但是Boost Locale比较特殊的地方是，它为多个有相同的功能的库提供了适配，当使用Boost Locale时，实际上使用的可能是它背后的任意一个库提供的功能，所以严格的来说，Boost Locale是一个**Locale前端**，或者也可以说是一个**门面**，总之是类似的概念，而在这个前端后面工作的，是**Locale后端**，支撑着Boost Locale的功能最全面、最强大的后端是ICU后端，这是IBM发起的一个本地化项目，为全球所有国家的本地化提供了支持，对文化的多个方面都有良好、全面的支持，而且在几乎所有常见的硬件架构和操作系统平台之间到处移植。

除此之外，Boost Locale还支持POSIX后端、Win Api后端和标准库后端，标准库后端在大多数情况下都没啥意义，POSIX后端和Win Api后端在可以在对应的平台上提供广泛的支持，但是也有各种限制，总的来说不如ICU后端全面、强大；

在处理字符编码上，ICU至少提供了以下几类实用的工具和功能：

* 一个字符串类`icu::UnicodeString`，这是一个更“符合直觉”的字符串类，它使用固定的内部字符类型和编码，并提供了一堆有用的方法和工具函数，其中包括一些与字符编码有关的操作：
  * 从特定编码构造字符串：ICU直接提供了`fromUTF8`和`fromUTF32`两个静态函数，除此之外，使用`setTo`方法和`UConvertor`的组合可以方便的从其它编码的字节数组转换并填充`UnicodeString`；
  * 转换到特定编码：ICU提供了`toUTF8`和`toUTF32`两个方法，但是与上一条相似的，对于ANSI字符串主要通过`setTo`方法支持的；
  * 检查码点数和字符单元数：由于内部通过UTF-16保存字符串，所以码点数和字符单元数可能不一致，`UnicodeString`可以根据代理对范围分析并给出实际的码点数；
  * 比较：支持多种比较，如精确二级制比较、基于区域比较器比较、码点比较、大小写不敏感比较、规范化比较等；
  * 分割：借助ICU定义的各种分割器，可以处理基于Locale的多种边界的字符串分割，并自动处理编码中的代理对和码点边界；
* 转换类`UConvertor`，该类定义一个字符转换工具类，并提供方法来在多种编码之间转换；
* 编码检测类`CharsetDetector`，用于检测一段字符数组可能的编码；

所以，直接使用ICU来处理字符串和转换字符串编码也是可行的，但是从统一接口这方面的要求来看，Boost Locale无疑是更好的；

需要注意的是，ICU也提供了自己的Locale类`icu::Locale`类，但是在ICU中，Locale并不包括编码转换功能，Locale名本身也不涉及编码；

除了通过`std::locale`类对象来获取`std::codecvt`对象以进行编码转换之外，Boost还在`boost::locale::conv`命名空间中提供了一组独立的提供了一组专用于编码转换的函数，相比于使用`std::codecvt`，这组独立函数至少有三个好处：

* 与特定的locale类型无关，可以独立地处理字符编码；
* `std::codecvt`的转换方法太复杂难用了，这种复杂主要体现在两个方面：需要用户自己管理缓冲区、需要用户自己检查转换过程中可能出现的错误并处理它们，而这组函数提供了简单的接口，且可以直接使用字符串类对象调用它们，并且通过一组枚举给出了转换错误的几种常见处理策略并在内部处理错误；
* 由于刻面实现的的问题，`std::codecvt`所提供的刻面往往是在多字节字符集和双/四字节字符集之间进行转换，对于在两个多字节字符集或双/四字节字符集之间的转换则有不便（需要找个中间编码，转换两次），这一组函数则提供了更灵活的接口，可以在一个调用之内完成转换，非常方便；

除了Boost之外，C++生态中的另外一个大库是Qt，作为自成一体的大平台，Qt也提供了处理字符编码的机制，从基本概念上来看，Qt与ICU比较相似：它们都使用内部固定编码的字符串（`UnicodeString`和`QString`都使用UTF-16），并使用字节数组统一处理多字节编码（Qt使用`QByteArray`而ICU直接把`std::string`当字节数组用），在这两类编码之外，它们都使用标准库的字符串模板，例如，对于UTF-32而言，它们都使用`std::u32string`。

在Qt中，其Locale类`QLocale`也不承担编码转换的职能，相反，Qt提供了一个单独的类`QTextCodec`来进行编码转换，`QTextCodec`提供了静态函数`codecFromName`来从特定的编码名称构建，并使用`fromUnicode`和`toUnicode`在Unicode字符编码和ANSI字符编码之间来回转换，除此之外，还用一组静态方法`QTextCodec::setCodecForCStrings()`和`QTextCodec::setCodecForTr()`可以控制`QString`从字符数组构造和从文本资源文件读取翻译文本的默认行为，因此，Qt也有一个默认的设置，在Qt 5.11.1之前，这个默认的编码是 Latin 1，在此之后，是UTF-8，伴随着这一变化发生的是`QTextCodec::setCodecForCStrings()`和`QTextCodec::setCodecForTr()`的移除，这背后反映的是Qt对于多字节字符集态度的转变：在更早的时候，Unicode还不是一个共识和主流的做法，Qt必须提供这些API以使用户可以将其定义为自己环境下的编码，这至少带来了两方面问题：

* 这些方法的作用都是全局的；
* 太多的教程滥用这些方法，使一部分开发人员在不知情的情况下修改全局设置，这可能破坏原来运行良好的代码；

（好吧这其实就是一个问题的不同阶段）

而在Qt 5.11这个时间点，Unicode在大多数平台上都达到了很好的支持，所以完全可以移除这些支持，使用Unicode更好地处理不同平台上的字符串了；

到了Qt6，整个`QTextCodec`类更是直接被移除，取而代之的是`QStringConvertor`类，这个行为与`QTextCodec::setCodecForCStrings()`和`QTextCodec::setCodecForTr()`的移除是一脉相承的：Qt认为在Qt6的这个时间节点，对大量旧的ANSI编码提供支持是不必要的，程序应当统一使用Unicode，因此在`QStringConvertor`的构造上也有更多限制：Qt保证支持的编码仅有Unicode编码、Latin 1和系统编码（在Linux上是UTF-8，在Windows上取决于代码页），因此不能像`QTextCodec`那样自由地通过编码名构造转换器，这对于需要这一行为地程序来说是一种退步。

需要注意的是，由于`QTextCodec`的移除，之前一些可以指定解码器的于文件操作相关的类型，如`QSettings`或`QTextStream`的相关API也弃用了，也就是说，在Qt6中，这些类也默认使用UTF-8且无法指定编解码器，如果要读取使用其它编码的文件，可能需要手动转换文件编码之后才能正常解析。

除了Boost、Qt这样的大库，还有一些不同规模的第三方也具备处理字符编码的能力，对于基于标准库字符串进行编码处理的库，一个常见的模式是提供一个特殊的迭代器，这个迭代器遍历字符串时，总是跳转到下一个码点边界上，UTF8-CPP就是这样对字符进行处理的，这种功能的优点在于可以不使用其它字符串类，对于已经大量使用标准库字符串的系统来说，这种方式的成本也比较低；

当然，UTF8-CPP仅仅处理几种Unicode编码，而**POCO**则在编码方面有更好的支持，虽然不像ICU那么全面，但它确实支持许多其它ANSI编码，比起UTF8-CPP来说实用性要更强。这类功能也不一定是独立的编码处理库或模块，Boost Locale提供了一个分词模块，这个模块本身的目的并非是简单的处理Unicode和其它ANSI字符码点，但是由于分词必须借助Locale的编码信息来识别边界，所以这个分词库也拥有类似的功能，虽然在Boost Locale中，使用上面提到的几种编码处理方式显然是更方便的。

在Qt6之后，Qt也通过一些处理特定编码的String View，例如QUtf8StringView，基本上可以将其视为迭代器模式的封装——视图在内部保存一个迭代器，并使其在码点边界之间跳转，从接口上看，视图会比迭代器更方便一些。
